---
title: "Multi-Level Linguistic Alignment in a Dynamic CPS Tasks: Step 3 Model 1"
author: "Nick Duran"
date: 10/14/21
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# rm(list=ls())
```

> Notebook contains code for replicating section in manuscript: Analysis 1: Alignment over time

### Step 1: Import main data file and run script to prep variables for analysis

```{r, warning=FALSE, message=FALSE, error=FALSE}
library(tidyverse)
library(pander)
```

```{r}
main.data = read.csv("../Data/Step1_PrepareFeatures.csv")

# test1 = main.data %>%
#   group_by(Team, School, Block, Level, revisited) %>%
#   filter(n() >= 20) %>%
#   ungroup()
#   
# ## remove extraordinarily long single utterances (removes 282 rows, or (282/34294)*100, or less than 1%)
# ## why 71? Because this is 5SDs above mean of utterlen: mean(main.data$utterlen_aligner)+(5*sd(main.data$utterlen_aligner))
# test2 = test1 %>% filter(utterlen_aligner < 71 & utterlen_target < 71)

source("../R_Helper/Step3_helper.R")
main.data.20 = variable_prep(main.data)

pander(names(main.data.20))
# head(main.data.20)
```

* Relies heavily on "Step3_helper.R." This code does the following:

  * remove levels that are fewer than 20 turns
  * Convert # of turns to a running proportion score 
  * Get z-scores for relevant variables
  * create ordered factor for block (interested in linear trend)
  * create random factor for within subject variance (making sure each unique subject is signified given their school and team)


https://seananderson.ca/2014/05/18/gamma-hurdle/. 

### Step 3: Build hurdle models: syntax

This step consists of a conditional model (y>0; non-zero positive values) and a 

Unlike count-based hurdle models,

The current study involves outcome variables in syntax and syntactic linguistic alignment have significant clumping at zero (see Figure X). To address this issue, we examine the zeros separately from the non-zeros in a hurdle model. This involves conducting a binomial logistic model for predicting the occurrence of nonzeros and a second model for evaluating the nonzero values. It is important to note that our outcome variable involves positive and continuous non-integers, and thus the gamma distribution is most appropriate in the second model, unlike more common count-based hurdle models that require a truncated count distribution (e.g., negative binomial, Poisson). 

<!-- Our solution for addressing the excess of zeros in the data is to separately model these from the non-zeros in a binomial-Gamma hurdle model. -->

```{r, warning=FALSE, message=FALSE, error=FALSE}
# library(glmmTMB) ## no longer using
library(lme4) ## for tab_model and plot_model
library(strengejacke) ## for tab_model
library(parameters)
library(lmtest) ## for lrtest
library(bbmle) ## for AICtab
```

##### setup for hurdle models

```{r}
GHM.data.20 = main.data.20 %>% mutate(non_zero_syn = ifelse(syntax > 0, 1, 0))
```

#### binomial logistic model 

To start, lets examine the binomial logistic model by first comparing two plausible random effect structures (while avoiding convergence issues).

Run the models: 

```{r}
z1.glmer1 <- glmer(non_zero_syn ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept + (1|subject_id), binomial(link = "logit"), data = GHM.data.20)
```

```{r}
z1.glmer2 <- glmer(non_zero_syn ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept + (aligner_role|subject_id), binomial(link = "logit"), data = GHM.data.20)
```

Compare the two models based on comparing log-likelihood/AIC with various tests. Using a couple of methods for my own learning and experimentations.

*   Some reading on these approaches:
    * AICtab approach recommended by Bolker et al for GLMMtmb type of approaches for model selection (note: does not attempt to give a p-value): https://journal.r-project.org/archive/2017/RJ-2017-066/RJ-2017-066.pdf

    * Another example of AICtab approach being used: http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html (scroll to section) http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html 

    * Suggestions on what to report when running an AICtab test: https://www.ashander.info/posts/2015/10/model-selection-glms-aic-what-to-report/

    * Expresses skepticism of relying too heavily on the p-value for the lrtest approach with generalized mixed models: https://www.ssc.wisc.edu/sscc/pubs/MM/MM_TestEffects.html#test-of-random-parameters
    
```{r}
# Method 1: AICtab
AICtab(z1.glmer1,z1.glmer2,logLik=TRUE)

#Method 2: lrtest
lrtest(z1.glmer1,z1.glmer2)

# Method 3: by hand
logLik(z1.glmer1)
logLik(z1.glmer2)
G2 = -2 * logLik(z1.glmer1) + 2 * logLik(z1.glmer2)
pchisq(as.numeric(G2), df=1, lower.tail=F)

# It appears that the more complex random effects structure explains slightly more variance.
```

Lets examine the summary structure of the preferred model, now focusing on the appropriateness of the random effects of the model. It does seem that the role|subject variance is very small. Is this variance relevant? Next step is to compare this effect with a model where we pool/ignore the role|subject effect. 

```{r}
summary(z1.glmer2)
```
The best that can be said is that the random and pooled have non identical log-likelihoods, and based on AIC, the random effect structure presents a slightly better model. 

```{r}
z1.glm2 <- glm(non_zero_syn ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept, binomial(link = "logit"), data = GHM.data.20)
```

```{r}
# Method 1: AICtab
AICtab(z1.glm2,z1.glmer2,logLik=TRUE)
```

Lastly, for random effects, let's compute the ICC value

```{r}
performance::icc(z1.glmer2)
```

Next, after making some observations about the random effects structure, lets see of the full model is better than the null model. Here we might be on more solid footing in using the LR-test. 

* Reading in this area that is supportive

    * Example of comparing Null and Full with hurdle modeling: https://link.springer.com/article/10.1007/s10940-020-09480-8#ref-CR77
    and https://link.springer.com/article/10.1007/s10940-020-09480-8/tables/4

```{r}
z1.glmer2.null <- glmer(non_zero_syn ~ 1 + (aligner_role|subject_id), binomial(link = "logit"), data = GHM.data.20)
```

```{r}
# Method 1: AICtab
AICtab(z1.glmer2.null,z1.glmer2,logLik=TRUE)
```

```{r}
#Method 2: lrtest
lrtest(z1.glmer2.null,z1.glmer2)
```

Let's get to interpreting the effects. These results can be reported as "log effect estimates" and exponentiated for "odds ratios." Here are two examples of how these have been reported that seem to make the most sense:

  * From Bolker: http://ms.mcmaster.ca/~bolker/misc/GLMM_results_report.pdf
  * From extortion victimization paper: https://link.springer.com/article/10.1007/s10940-020-09480-8
  * For generally reporting and intepreting mixed effects models: http://www.singmann.org/download/publications/singmann_kellen-introduction-mixed-models.pdf

```{r}
model_parameters(z1.glmer2, exponentiate = T, digits=3)
# VarCorr(z1.glmer2)
```





#### gamma model

```{r}
g1.glmer1 <- glmer(syntax ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept + (1|subject_id), family = Gamma(link = log), data = subset(GHM.data.20, non_zero_syn == 1), control=glmerControl(optimizer="bobyqa"))
```

```{r}
g1.glmer2 <- glmer(syntax ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept + (aligner_role|subject_id), family = Gamma(link = log), data = subset(GHM.data.20, non_zero_syn == 1), control=glmerControl(optimizer="bobyqa"))
```

Compare the two models based on comparing log-likelihood/AIC with various tests. Using a couple of methods for my own learning and experimentation.

```{r}
# Method 1: AICtab
AICtab(g1.glmer1,g1.glmer2,logLik=TRUE)

#Method 2: lrtest
lrtest(g1.glmer1,g1.glmer2)

# Method 3: by hand
logLik(g1.glmer1)
logLik(g1.glmer2)
G2 = -2 * logLik(g1.glmer1) + 2 * logLik(g1.glmer2)
pchisq(as.numeric(G2), df=1, lower.tail=F)

# It appears that the more complex random effects structure explains slightly more variance.
```

Lets examine the summary structure of the preferred model, now focusing on the appropriateness of the random effects of the model. Again, role|subject variance is very small. Is this variance relevant? Next step is to compare this effect with a model where we pool/ignore the role|subject effect. 

```{r}
summary(g1.glmer2)
```

The best that can be said is that the random and pooled have non identical log-likelihoods, and based on AIC, the random effect structure presents a slightly better model. 

```{r}
g1.glm2 <- glm(syntax ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept, family = Gamma(link = log), data = subset(GHM.data.20, non_zero_syn == 1))
```

```{r}
# Method 1: AICtab
AICtab(g1.glm2,g1.glmer2,logLik=TRUE)
```

Lastly, for random efffects, let's compute the ICC value

```{r}
performance::icc(g1.glmer2)
```

Next, after making some observations about the random effects structure, lets see of the full model is better than the null model. Here we might be on more solid footing in using the LR-test. 

```{r}
g1.glmer2.null <- glmer(syntax ~ 1 + (aligner_role|subject_id), family = Gamma(link = log), data = subset(GHM.data.20, non_zero_syn == 1), control=glmerControl(optimizer="bobyqa"))
```

```{r}
# Method 1: AICtab
AICtab(g1.glmer2.null,g1.glmer2,logLik=TRUE)
```

```{r}
#Method 2: lrtest
lrtest(g1.glmer2.null,g1.glmer2)
```

Let's get to interpreting the effects. These results can be reported as "log effect estimates" and exponentiated for "odds ratios." 

```{r, warning=FALSE, message=FALSE}
model_parameters(g1.glmer2, exponentiate = T, digits=3)
# VarCorr(g1.glmer2)
```
```{r}
# library(jtools)
# summ(g1.glmer2,confint = TRUE, digits = 3, vifs = TRUE)
```

```{r}

```

There is also the issue of over-dispersion that we could test or examine, but might be overkill given gamma distribution accounts for overdispersion. 

  * library(aods3); gof()
  
  

#### Create Visuals for Better Presentation

Let's start with rate incidence/odds ratio as a forest plot using "plot_model" with modifications

```{r}
pz.s = plot_model(z1.glmer2, show.values = TRUE, value.offset = .4,
                  group.terms = c(1,1,2,2,2,2,2),
                  rm.terms = c("Block.l.Q"),  
                  axis.labels = c("ordering_prop"="Utterance order", "Block.l.L"="Block (linear trend)", "aligner_rolecontroller"="Role [controller]", "relative_start_timeZ"="Level start time", "level_durationZ"="Level duration", "utterlen_alignerZ"="Utterance length", "ConceptPoT" = "Concept [PoT]"),
                  # title=c("syntax Alignment"),
                  digits = 3) + 
                  labs(title = "Syntax Alignment",
                  subtitle = "Binomial Logistic Mixed Effects")

pz.s = pz.s + ylim(.5, 3) + 
  geom_hline(yintercept =1, linetype=3) + 
  theme_bw() +
  theme(
        plot.title=element_text(size=16,face="bold"), # theme_light()
        axis.text.y=element_text(size=12),
        axis.ticks.y=element_blank(),
        axis.text.x=element_text(face="bold"),
        axis.title=element_text(size=12,face="bold"),
        strip.text.y = element_text(hjust=0,vjust = 1,angle=180,face="bold"))
pz.s
```

```{r}
pg.s = plot_model(g1.glmer2, show.values = TRUE, value.offset = .4,
                  group.terms = c(1,1,2,2,2,2,2),
                  rm.terms = c("Block.l.Q"),  
                  axis.labels = c("ordering_prop"="Utterance order", "Block.l.L"="Block (linear trend)", "aligner_rolecontroller"="Role [controller]", "relative_start_timeZ"="Level start time", "level_durationZ"="Level duration", "utterlen_alignerZ"="Utterance length", "ConceptPoT" = "Concept [PoT]"),
                  title=c(""),
                  digits = 3) + 
                  labs(title = "",
                  subtitle = "Gamma Mixed Effects",
                  caption = expression(paste("Significance: ***", italic("p"), "<.001, **", italic("p"), "<.001, *", italic("p"), "<.05")))

pg.s = pg.s + ylim(.85, 1.15) + 
  geom_hline(yintercept =1, linetype=3) + 
  theme_bw() + 
  theme(plot.title=element_text(size=16,face="bold"), # theme_light()
        # axis.text.y=element_text(size=12),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x=element_text(face="bold"),
        axis.title=element_text(size=12,face="bold"),
        # plot.caption = element_text(hjust = 0),
        strip.text.y = element_text(hjust=0,vjust = 1,angle=180,face="bold"))
pg.s
```

```{r}
library(patchwork)
pz.s + pg.s
```

Customize my own forest plots, but this is really cumbersome and long to do what the above does much more elegantly.

```{r}
# #Need to prep the input tables. 

# gdf = data.frame(model_parameters(g1.glmer2, exponentiate = T)) %>% select(-t) %>% mutate(Model="Gamma Mixed Effects")
# zdf = data.frame(model_parameters(z1.glmer2, exponentiate = T)) %>% select(-z) %>% mutate(Model="Binomial Logistic Mixed Effects")
# df.lex = rbind(zdf, gdf)
# 
# df.lex2 = df.lex %>% mutate_if(is.numeric, round, digits = 3) %>%
#   mutate(Group = case_when(Parameter == "ordering_prop" | Parameter == "Block.l.L" ~ 
#                 "Main Predictors", 
#                 TRUE ~ "Covariates"),
#          p.vales = ifelse(p < .001, "***",
#                    ifelse(p < .01 & p >= .001, "**",
#                    ifelse(p < .05 & p >= .01, "*", "")))) %>%
#   ## just get parameters and columns that are needed
#   filter(Effects == "fixed" &  Parameter != "Block.l.Q" & Parameter != "(Intercept)") %>%
#   select(Parameter, Coefficient, CI_low, CI_high, Group, Model, p.vales) %>%
# ## reorder parameters
#   group_by(Model) %>%
#   mutate(Parameter=factor(Parameter)) %>% 
#   group_by(Model) %>%
#   mutate(Parameter=fct_relevel(Parameter,c("ConceptPoT", "aligner_rolecontroller", "utterlen_alignerZ", "relative_start_timeZ", "level_durationZ", "Block.l.L", "ordering_prop"))) %>%
#   arrange(Parameter) %>%
#   ungroup()
# 
# df.lex2$Parameter = recode_factor(df.lex2$Parameter, "ConceptPoT" = "Concept [PoT]", "aligner_rolecontroller"="Role [controller]", "utterlen_alignerZ"="Utterance length", "relative_start_timeZ"="Level start time", "level_durationZ"="Level duration", "Block.l.L"="Block (linear trend)", "ordering_prop"="Utterance order")
```

Create function for generating forest plots

```{r}
# # https://datascienceplus.com/lattice-like-forest-plot-using-ggplot2-in-r/
# # https://billobrien.wordpress.com/2018/04/05/__trashed/
# # https://stackoverflow.com/questions/62246541/forest-plot-with-table-ggplot-coding
# 
# forest_indiv <- function(form_df, wrapit=FALSE) {
#    
#     plot1 = ggplot(data=form_df,
#     aes(x = Parameter,y = Coefficient, ymin = CI_low, ymax = CI_high))+
#     # geom_point(size=3, shape=19)+ # use only if not going to use color
#     geom_pointrange(aes(col=Group), show.legend = FALSE)+ ## this is good, but creates a legend
#     geom_hline(aes(fill=Parameter), yintercept =1, linetype=3)+
#     xlab('Parameter') + ylab("95% Confidence Interval")+
#     geom_errorbar(aes(ymin=CI_low, ymax=CI_high,col=Group), show.legend = FALSE, width=0,cex=.5)+ 
#     geom_text(aes(x = Parameter, label =  paste0(Coefficient, p.vales)), nudge_x = .35) + #size=3
#     coord_flip() + 
# 
#     theme(plot.title=element_text(size=16,face="bold"),
#         axis.text.y=element_text(size=12),
#         axis.ticks.y=element_blank(),
#         axis.text.x=element_text(face="bold"),
#         axis.title=element_text(size=12,face="bold"),
#         strip.text.y = element_text(hjust=0,vjust = 1,angle=180,face="bold"))+
#       
#     if (wrapit == TRUE) {
#       facet_grid(~Model,scales = "free",switch="y")
#     }
#     return(plot1)
# }
```
 
```{r}
# p1.1 = forest_indiv(filter(df.lex2, Model=="Binomial Logistic Mixed Effects")) + ggtitle("syntax\nBinomial Logistic Mixed Effects") + ylim(.5, 2.5)
# p1.1
```

```{r}
# p1.2 = forest_indiv(filter(df.lex2, Model=="Gamma Mixed Effects")) + ggtitle("syntax\nGamma Mixed Effects") + 
#   theme(axis.text.y=element_blank(),
#         axis.title.y=element_blank()) + 
#   ylim(.85, 1.15)
# p1.2
```
 
```{r}
# # p3 = forest_indiv(df.lex2, wrapit=TRUE); p3
# p1.1 + p1.2
```





#### coefficient table w/ tab_model

```{r}
# tab_model(zigamma_lex, zigamma_syn2nd,
#           show.ci = 0.95, #FALSE
#           rm.terms = c("Block.l.Q"),
#           pred.labels = c("ordering_prop"="Utterance order", "Block.l.L"="Block (linear trend)", "BlockExpBlock2"="Block 2 (vs Warmup)", "aligner_rolecontroller"="Role [controller]", "relative_start_timeZ"="Level start time", "level_durationZ"="Level duration", "utterlen_alignerZ"="Utterance length", "ConceptPoT" = "Concept [PoT]", "Revisited_birevisit" = "Revisit [yes]", "XQ_know"="Familiarity [yes]", "femdomin"="Majority Female [yes]"),
#           # title = "",
#           digits = 3,
#           digits.re = 3,
#           dv.labels = c("syntax", "Syntactic"),
#           show.re.var = TRUE,
#           use.viewer = TRUE)

```



#### glmmTMB approach

To start, going to build with a glmmTMB model that allows random effect structure. We are going to use the gamma distribution because we are dealing with non-integer (non-count) data as our DV and thus is continuously distributed, with some skew in the positive direction. Starting with the simplest random effect structure model with subject. 

```{r}
# zigamma_lex2 <- glmmTMB(syntax ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept + (aligner_role|subject_id),
#                          family = ziGamma(link = "log"), 
#                          ziformula = ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept + (aligner_role|subject_id),
#                          data = main.data.20)
```







Analytical Strategy:

A gamma distribution that accounts for overdispersion...  

Prevalance and degree of alignment. 

Multilevel gamma hurdle model (MGH). They allow the specification of distinct probability functions for observations where y=0, and y>0. That is, examines the probability of observing a zero count, and if the hurdle is crossed (if y>0), then we examine the truncated density. 

Binary model. 

An advantage of the hurdle model is that its components (the prevalence and truncated models) can be estimated separately (independently). 

"However, when observations are clustered and random effects are used, as in the multilevel approach used here, the two stage estimation procedure assumes that group random effects for prevalence and concentration are independent, when in fact they may be correlated." 

All models were estimated using the "glmmTMB" package. 

"We estimated the standard MNB model as a baseline to compare the estimates of the MNB-LH model.

"For count MNB and MTNB models, the exponentiated estimates represent incidence rate ratios (IRR, Hilbe 2014, p. 60), whereas for the binary ML model they represent odds ratios (OR, Weisburd and Britt 2014, p. 568). Subtracting 1 from the IRR (𝐼𝑅𝑅−1) gives the percentage change on the concentration of extortion victimization for a one unit increase in the independent variable, while 𝑂𝑅−1 gives the percentage change in the prevalence risk. For categorical independent variables, the percentage change is relative to the reference category."




Zero-inflated model:
For predicting the likelihood of zero alignment as conversational turns progress in a level, there was no statistically significant difference over time (log effect estimate = 0.021, Wald CI: { }). However, at the broader scale, when collapsed across rounds, the later rounds showed a higher incidence of zero alignment, with an approximately 7.11% (log effect estimate: ) increase of zero values (Wald CI: { }). The estimate of participant-level variance, taking into account role as a controller or observer, was ..., indicating very little variation among subjects, with a 95% Wald CI of { }.   

Conditional model:
For the conditional model based on the distribution of syntax alignment values greater than zero, a	1 unit increase at the scale of	turn order (from the start to end of the level)	was	associated with a 2.93% reduction (log effect estimate: -0.030) in the mean of syntax alignment (95% Wald CI={}). The change over the larger scale of rounds was not statistically significant (log effect estimate = 0.021, 95% Wald CI={}). The among-subject standard deviation was again small, at ..., with a 95% Wald CI of { }.  

The statistical significance for the co-variates in the zero-inflated and conditional models were very similar. For the zero-inflated model (likelihood of zero syntax alignment vs any syntax alignment), ...  

For the distribution of syntax alignment of values greater than zero, ... 



```{r}
summary(zigamma_lex2)
```



any syntax alignment (values greater than 0), there was no change of likelihood as turns progressed within an level. That is, the odds of there being no alignment based on turn position was not statistically significantly different than there being alignment. But over the larger scale of rounds (linear trend from 1st to 3rd round), the odds of there being no syntax alignment increased by 7.11% (log effect estimate: -0.030). That is, there was an 7.11% increase in having no occurrence of syntax alignment by the final round.   



	“A	1%	increase	in	
seroprevalence	was	associated	with	an	approximately	2.1%	increase	(log	effect	
estimate=0.021)	in	the	density	of	fresh	shells	(95%	CI={0.013,0.031}	by	parametric	
bootstrap	[PB]).	Both	of	the	years	subsequent	to	2004	had	lower	shell	densities	(logdifference	=-0.64	(2005),	-0.43	(2006)),	but	the	differences	were	not	statistically	
significant	(95%	PB	CI:	2005={1.34,0.05},	2006={-1.04,0.18}).	There	was	no	detectable	
overdispersion	(Pearson	squared	residuals/residual	df=0.85;	estimated	variance	of	an	
among-observation	random	effect	was	zero).	The	best	estimate	of	among-site	standard	
deviation	was	zero,	indicating	no	discernable	variation	among	sites,	with	a	95%	PB	CI	of	
{0,0.38}.”






For the **linear component (gamma)** component, assuming a non-zero value, a 1 unit increase in ordering_prop (from the start [0] to the end [1]) leads to a 0.97 decrease in the mean of syntax. Put in another way, increasing ordering_prop 0 to 1 (start to finish) causes a 2.93% (1-(exp(-0.0297724))) * 100 reduction in the mean amount of syntax alignment. Or, we can change the unit size to .10 increments. If so, increasing ordering_prop by 1/10 increments causes a 0.30% (1-exp(-0.0297724 * 0.1)) * 100 reduction in the mean amount of syntax.

For the **binomial component** predicting whether syntax alignment occurred at all, although no change of likelihood across a level, for likelihood across blocks, the odds of there being no syntax alignment increased by 1.07 times exp(0.0686873). That is, there was an 7.11% increase in having no occurrence of syntax alignment by the final round.


#### How to interpret (generally): 

For the **linear component (gamma)**, we use a log link that allows us to predict the model-adjusted mean of the non-zero data on the log scale. Being on the log scale, we can also exponentiate to make claims about how a unit increase in response value x leads to a probabilistic decrease or increase in the mean of the outcome. For example: A 1 unit increase in x leads to a 0.012 decrease in the mean of the outcome. Put another way, increasing x by 1 causes a 98.8% reduction in the predictor. 

For the **binomial component** we use a logit link to predict "0" (nonoccurrence) and then exponentiate the resulting coefficient to report the probability of seeing a nonoccurrence. 











Ok, new notes from 11/19/21:

A very good paper for just talking about the random effect structure of LMER models, ensures that what is being reported is accurate and gives a critical citation: http://www.singmann.org/download/publications/singmann_kellen-introduction-mixed-models.pdf

An interesting discussion of how to determine whether the random effects variables are worth including, whether a mixed effects model is even necessary. Brings up the interesting idea of using models with and without the effect and comparing with AIC
https://stats.stackexchange.com/questions/56150/how-can-i-test-whether-a-random-effect-is-significant

In one of the responses to the main thread, a very good point that "although there is 'obviously' variation in subject performance, the extent of this subject variation can be fully or virtually-fully explained by just the residual variance term alone. There is not enough additional subject-level variation to warrant adding an additional subject-level random effect to explain all the observed variation."
https://stats.stackexchange.com/questions/115090/why-do-i-get-zero-variance-of-a-random-effect-in-my-mixed-model-despite-some-va

Not the greatest post, but makes the point that gamma works on continuous non-negative distributions, whereas poisson and negative binomial do not:
https://timothy-barry.github.io/posts/2020-06-16-gamma-poisson-nb/

********Topic: Overdispersion
Not sure whether I need to explicity test for this or not, as visually, it appears to be overdispersed. However, need to plot the residuals to know for sure. So, strike previous comment. Cannot merely plot the DV to make a determination. 
Just ok resources but useable to back up some claims. 
https://biometry.github.io/APES/LectureNotes/2016-JAGS/Overdispersion/OverdispersionJAGS.pdf
https://biometry.github.io/APES//LectureNotes/2016-JAGS/Overdispersion/OverdispersionJAGS.html

*******Topic: "How to model non-negative zero-inflated continuous data?"
Given this is exactly what I'm trying to do, this thread was helpful and pointed to the need of running zero-inflated/hurdle models (i.e., two-part models) 
https://stats.stackexchange.com/questions/187824/how-to-model-non-negative-zero-inflated-continuous-data

But this post also suggests running a model where you run the two parts yourself rather than relying on a single function, like glmmTMB, especially if I want to build a model without the random effects structure. This tutorial shows you how:
https://seananderson.ca/2014/05/18/gamma-hurdle/

This seananderson paper is really useful as it does make the points that most packages are built for count data (and he lists a bunch of these options), but this doesn't help me much. He also reinforces the point that what is needed are binomial-Gamma hurdle models. 

Use this paper when citing glmmTMB models:
https://journal.r-project.org/archive/2017/RJ-2017-066/RJ-2017-066.pdf









