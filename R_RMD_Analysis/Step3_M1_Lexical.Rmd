---
title: "Multi-Level Linguistic Alignment in a Dynamic CPS Tasks: Step 3 Model 1: Lexical"
author: "Nick Duran"
date: 03/28/22
output: html_document
---

```{r global-options, include=FALSE}
knitr::opts_chunk$set(fig.path='Figs/',
                      warning=FALSE, message=FALSE, error=FALSE)
```
<!-- # echo=FALSE : suppress all the code but show text/results output -->
<!-- # results='hide' : show code but hide the text/results output -->
<!-- # fig.show='hide' : hide figures -->

> Notebook contains code for replicating section in manuscript: Analysis 1: Alignment over time

### Step 1: Import main data file and run script to prep variables for analysis

```{r}
library(tidyverse)
library(pander)

rm(list=ls())
```

```{r}
###### REAL DATA : BE SURE TO UPDATE NAMES OF THE SAVED OUTPUT FILES ########
main.data = read.csv("../Data/Step1_PrepareFeatures.csv")

###### BASELINE DATA FOR COMPARISON : BE SURE TO UPDATE NAMES OF THE SAVED OUTPUT FILES ########
# main.data = read.csv("../Data/Step1_PrepareFeatures_Baseline.csv")

source("../R_Helper/Step3_helper.R")
main.data.20 = variable_prep(main.data)

pander(names(main.data.20))
# head(main.data.20)
```

* Relies heavily on "Step3_helper.R." This code does the following:

  * remove levels that are fewer than 20 turns
  * Convert # of turns to a running proportion score 
  * Get z-scores for relevant variables
  * create ordered factor for block (interested in linear trend)
  * create random factor for within subject variance (making sure each unique subject is signified given their school and team)

### Step 2: Check the distributions of the main outcome linguistic variables

```{r, echo=FALSE}
g1 = main.data.20 %>% select(lexical, syntax, semantic) %>% pivot_longer(lexical:semantic, "align") %>% mutate(align=factor(align)) %>% mutate(align=fct_relevel(align, c("lexical", "syntax", "semantic")))
align.labels = c("Lexical", "Syntax", "Semantic")
names(align.labels) = c("lexical", "syntax", "semantic")
ggplot(g1, aes(x=value))+
  geom_histogram(binwidth=0.05)+
  facet_wrap(~align, labeller = labeller(align = align.labels), scales = "free")+
  # labs(title="Distribution of Alignment Scores",x="Align Value (Cosine)", y = "Frequency") +
  labs(y = "Frequency") +
  theme_bw() + 
  theme(plot.title=element_text(size=14,face="bold"), # theme_light()
  #       axis.text.y=element_text(size=12),
        axis.ticks.y=element_blank(),
  #       axis.text.x=element_text(size=12, face="bold"),
  #       axis.title=element_text(size=12,face="bold"),
  #       # plot.caption = element_text(hjust = 0),
  #       # strip.text.y = element_text(hjust=0,vjust = 1,angle=180,face="bold"),
    axis.line = element_line(color = "#3D4852"),
    axis.ticks = element_line(color = "#3D4852"),
    panel.grid.major.y = element_line(color = "#DAE1E7"),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.y = element_blank()
  )
# ggsave("Figs/histogram.pdf")
# ggsave("Figs/histogram_baseline.pdf")
```

```{r, echo=FALSE}
# ggsave(filename = "Figs/histogram.png",width = 6, height = 3, dpi = 300, units = "in", device='png')
```

```{r, echo=FALSE}
# What is just the overall amount of alignment for each linguistic type?
# summtab = main.data.20 %>% 
#   select(Block, lexical, syntax, semantic) %>%
#   group_by(Block) %>%
#   summarise(across(everything(), .f = list(mean = mean, sd = sd), na.rm = TRUE))
# pander(summtab, digits=3)
```

```{r}
g1 = main.data.20 %>% select(lexical, syntax, semantic)
head(g1)
```

<!-- Logistic regression coefficients come out on the logit scale -->
<!-- Gamma coefficients are on a log-scale  -->
<!-- Both can be exponentiated to produce odds-ratios.  -->

<!-- For a gamma model with a log link, you would be modelling the log expected value of a (strictly positive) continuous response variable but the interpretation of the regression coefficient for a predictor would be similar to what I described above. -->

### Step 3: Build and test models: Lexical

<!-- Our solution for addressing the excess of zeros in the data is to separately model these from the non-zeros in a binomial-Gamma hurdle model. -->

```{r, results='hide'}
# library(glmmTMB) ## no longer using
library(lme4) ## for glmer 
library(strengejacke) ## for tab_model and plot_model
library(parameters)
library(lmtest) ## for lrtest
library(bbmle) ## for AICtab
```

Setup for separating prevalence from magnitude

```{r}
GHM.data.20 = main.data.20 %>% mutate(non_zero_lex = ifelse(lexical > 0, 1, 0))
```
<!-- ## we want to predict nonzero values, therefore must set reference to ZERO (glmer does this by default) -->
<!-- # GHM.data.20$non_zero_lex = relevel(factor(GHM.data.20$non_zero_lex), ref="ZERO") -->

####################################################################################################
####################################################################################################

#### Binomial logistic model 

##### Model selection tests: interceptVSslope

To start, lets examine the binomial logistic model by first comparing two plausible random effect structures (while avoiding convergence issues).

Run the models: 

```{r}
z1.glmer1 <- glmer(non_zero_lex ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept + (1|subject_id), binomial(link = "logit"), data = GHM.data.20)
```

```{r}
z1.glmer2 <- glmer(non_zero_lex ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept + (aligner_role|subject_id), binomial(link = "logit"), data = GHM.data.20)
```

Compare the two models based on comparing log-likelihood/AIC with various tests. 

```{r}
# AICtab
AICtab(z1.glmer1,z1.glmer2,logLik=TRUE)
```

```{r}
# lrtest
lrtest(z1.glmer1,z1.glmer2)
```

##### Model selection tests: randomVSnone

Lets examine the summary structure of the preferred model, now focusing on the appropriateness of the random effects of the model. It does seem that the role|subject variance is very small. Is this variance relevant? Next step is to compare this effect with a model where we pool/ignore the role|subject effect. 

```{r}
summary(z1.glmer2)
```

The best that can be said is that the random and pooled have non identical log-likelihoods, and based on AIC, the random effect structure presents a slightly better model. 

```{r}
z1.glm2 <- glm(non_zero_lex ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept, binomial(link = "logit"), data = GHM.data.20)
```

```{r}
# AICtab
AICtab(z1.glm2,z1.glmer2,logLik=TRUE)

#Method 2: lrtest : CANNOT RUN THIS TEST BECAUSE TWO DIFFERENT MODEL CLASSES! 
```

<!-- Lastly, for random efffects, let's compute the ICC value -->

```{r, echo=FALSE, results='hide'}
performance::icc(z1.glmer2)
```

##### Model selection tests: fullVsnull

Next, after making some observations about the random effects structure, lets see of the full model is better than the null model. Here we might be on more solid footing in using the LR-test. 

<!-- * Reading in this area that is supportive -->
<!--     * Example of comparing Null and Full with hurdle modeling: https://link.springer.com/article/10.1007/s10940-020-09480-8#ref-CR77 -->
<!--     and https://link.springer.com/article/10.1007/s10940-020-09480-8/tables/4 -->

```{r}
z1.glmer2.null <- glmer(non_zero_lex ~ 1 + (aligner_role|subject_id), binomial(link = "logit"), data = GHM.data.20)
```

```{r}
# AICtab
AICtab(z1.glmer2.null,z1.glmer2,logLik=TRUE)
```

```{r}
# lrtest
lrtest(z1.glmer2.null,z1.glmer2)
```

##### Interpreting

Let's get to interpreting the effects. These results can be reported as "log effect estimates" and exponentiated for "odds ratios." 

<!-- Here are several examples of how these have been reported that seem to make the most sense: -->
<!--   * From Bolker: http://ms.mcmaster.ca/~bolker/misc/GLMM_results_report.pdf -->
<!--   * From extortion victimization paper: https://link.springer.com/article/10.1007/s10940-020-09480-8 -->
<!--   * For generally reporting and intepreting mixed effects models: http://www.singmann.org/download/publications/singmann_kellen-introduction-mixed-models.pdf -->

```{r}
# model_parameters(z1.glmer2, exponentiate = T, digits=3)
```

```{r}
model_parameters(z1.glmer2, exponentiate = F, digits=3)

# Now generating the % change from the non-exponentiated coefficients to facilitate reporting 
(1-(exp(-0.068))) * 100
```



####################################################################################################
####################################################################################################

#### Gamma models

##### Model selection tests: interceptVSslope

```{r}
g1.glmer1 <- glmer(lexical ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept + (1|subject_id), family = Gamma(link = log), data = subset(GHM.data.20, non_zero_lex == 1), control=glmerControl(optimizer="bobyqa"))
```

```{r}
g1.glmer2 <- glmer(lexical ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept + (aligner_role|subject_id), family = Gamma(link = log), data = subset(GHM.data.20, non_zero_lex == 1), control=glmerControl(optimizer="bobyqa"))
```

Compare the two models based on comparing log-likelihood/AIC with various tests. 

```{r}
# AICtab
AICtab(g1.glmer1,g1.glmer2,logLik=TRUE)

# lrtest
lrtest(g1.glmer1,g1.glmer2)
```

##### Model selection tests: randomVSnone

Lets examine the summary structure of the preferred model, now focusing on the appropriateness of the random effects of the model. Again, role|subject variance is very small. Is this variance relevant? Next step is to compare this effect with a model where we pool/ignore the role|subject effect. 

```{r}
summary(g1.glmer2)
```

The best that can be said is that the random and pooled have non identical log-likelihoods, and based on AIC, the random effect structure presents a slightly better model. 

```{r}
g1.glm2 <- glm(lexical ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept, family = Gamma(link = log), data = subset(GHM.data.20, non_zero_lex == 1))
```

```{r}
# AICtab
AICtab(g1.glm2,g1.glmer2,logLik=TRUE)
```

Lastly, for random efffects, let's compute the ICC value

```{r, echo=FALSE, results='hide'}
performance::icc(g1.glmer2)
```

##### Model selection tests: fullVsnull

Next, after making some observations about the random effects structure, lets see of the full model is better than the null model. Here we might be on more solid footing in using the LR-test. 

```{r}
g1.glmer2.null <- glmer(lexical ~ 1 + (aligner_role|subject_id), family = Gamma(link = log), data = subset(GHM.data.20, non_zero_lex == 1), control=glmerControl(optimizer="bobyqa"))
```

```{r}
# AICtab
AICtab(g1.glmer2.null,g1.glmer2,logLik=TRUE)
```

```{r}
# lrtest
lrtest(g1.glmer2.null,g1.glmer2)
```

##### Interpreting

Let's get to interpreting the effects. These results can be reported as "log effect estimates" and exponentiated for "odds ratios." 

```{r}
# model_parameters(g1.glmer2, exponentiate = T, digits=3)
```

```{r}
model_parameters(g1.glmer2, exponentiate = F, digits=3)

# (1-(exp(-0.035))) * 100
```

####################################################################################################
####################################################################################################

### Step 4: Create visuals

Let's start with rate incidence/odds ratio as a forest plot using "plot_model" with modifications

```{r, echo=FALSE, fig.show='hide'}
pz.l = plot_model(z1.glmer2, show.values = TRUE, value.offset = .4,
                  group.terms = c(1,1,2,2,2,2,2),
                  rm.terms = c("Block.l.Q"),  
                  axis.labels = c("ordering_prop"="Utterance order", "Block.l.L"="Block (linear trend)", "aligner_rolecontroller"="Role [controller]", "relative_start_timeZ"="Level start time", "level_durationZ"="Level duration", "utterlen_alignerZ"="Utterance length", "ConceptPoT" = "Concept [PoT]"),
                  # title=c("Lexical Alignment"),
                  dot.size=2,
                  digits = 3) + 
                  labs(title = "Lexical Alignment",
                  subtitle = "Binomial Logistic Mixed Effects")

pz.l = pz.l + ylim(.5, 2.45) + 
  geom_hline(yintercept =1, linetype=3) + 
  theme_bw() +
  theme(
        plot.title=element_text(size=16,face="bold"), # theme_light()
        axis.text.y=element_text(size=10),
        # axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x=element_text(face="bold"),
        axis.title=element_text(size=12,face="bold"),
        strip.text.y = element_text(hjust=0,vjust = 1,angle=180,face="bold"))
pz.l
```

```{r, echo=FALSE, fig.show='hide'}
pg.l = plot_model(g1.glmer2, show.values = TRUE, value.offset = .4,
                  group.terms = c(1,1,2,2,2,2,2),
                  rm.terms = c("Block.l.Q"),  
                  axis.labels = c("ordering_prop"="Utterance order", "Block.l.L"="Block (linear trend)", "aligner_rolecontroller"="Role [controller]", "relative_start_timeZ"="Level start time", "level_durationZ"="Level duration", "utterlen_alignerZ"="Utterance length", "ConceptPoT" = "Concept [PoT]"),
                  title=c(""),
                  dot.size=2,
                  digits = 3) + 
                  labs(title = "",
                  subtitle = "Gamma Mixed Effects")
                  # caption = expression(paste("Significance: ***", italic("p"), "<.001, **", italic("p"), "<.001")))

pg.l = pg.l + ylim(.85, 1.15) + 
  scale_y_continuous(name="Rate Ratios") +
  geom_hline(yintercept =1, linetype=3) + 
  theme_bw() + 
  theme(plot.title=element_text(size=16,face="bold"), # theme_light()
        # axis.text.y=element_text(size=12),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x=element_text(face="bold"),
        axis.title=element_text(size=12,face="bold"),
        # plot.caption = element_text(hjust = 0),
        strip.text.y = element_text(hjust=0,vjust = 1,angle=180,face="bold"))
pg.l 
```

```{r}
library(patchwork)
alignPlotLex = pz.l + pg.l
alignPlotLex
# alignPlotLex + plot_annotation(tag_levels = 'A')
```

```{r, echo=FALSE}
# ggsave(filename = "Figs/lexical_forest.png",width = 8, height = 4.5, dpi = 300, units = "in", device='png')
# ggsave(filename = "Figs/lexical_forest_baseline.png",width = 8, height = 4.5, dpi = 300, units = "in", device='png')

```

```{r, echo=FALSE}
save.image(file = "lexical.RData")
# save.image(file = "lexical_baseline.RData")
```







<!-- Everything below can be ignored but keeping for historical purposes and record-keeping -->

<!-- Customize my own forest plots, but this is really cumbersome and long to do what the above does much more elegantly. -->

```{r, echo=FALSE}
# #Need to prep the input tables. 

# gdf = data.frame(model_parameters(g1.glmer2, exponentiate = T)) %>% select(-t) %>% mutate(Model="Gamma Mixed Effects")
# zdf = data.frame(model_parameters(z1.glmer2, exponentiate = T)) %>% select(-z) %>% mutate(Model="Binomial Logistic Mixed Effects")
# df.lex = rbind(zdf, gdf)
# 
# df.lex2 = df.lex %>% mutate_if(is.numeric, round, digits = 3) %>%
#   mutate(Group = case_when(Parameter == "ordering_prop" | Parameter == "Block.l.L" ~ 
#                 "Main Predictors", 
#                 TRUE ~ "Covariates"),
#          p.vales = ifelse(p < .001, "***",
#                    ifelse(p < .01 & p >= .001, "**",
#                    ifelse(p < .05 & p >= .01, "*", "")))) %>%
#   ## just get parameters and columns that are needed
#   filter(Effects == "fixed" &  Parameter != "Block.l.Q" & Parameter != "(Intercept)") %>%
#   select(Parameter, Coefficient, CI_low, CI_high, Group, Model, p.vales) %>%
# ## reorder parameters
#   group_by(Model) %>%
#   mutate(Parameter=factor(Parameter)) %>% 
#   group_by(Model) %>%
#   mutate(Parameter=fct_relevel(Parameter,c("ConceptPoT", "aligner_rolecontroller", "utterlen_alignerZ", "relative_start_timeZ", "level_durationZ", "Block.l.L", "ordering_prop"))) %>%
#   arrange(Parameter) %>%
#   ungroup()
# 
# df.lex2$Parameter = recode_factor(df.lex2$Parameter, "ConceptPoT" = "Concept [PoT]", "aligner_rolecontroller"="Role [controller]", "utterlen_alignerZ"="Utterance length", "relative_start_timeZ"="Level start time", "level_durationZ"="Level duration", "Block.l.L"="Block (linear trend)", "ordering_prop"="Utterance order")
```

<!-- Create function for generating forest plots -->

```{r, echo=FALSE}
# # https://datascienceplus.com/lattice-like-forest-plot-using-ggplot2-in-r/
# # https://billobrien.wordpress.com/2018/04/05/__trashed/
# # https://stackoverflow.com/questions/62246541/forest-plot-with-table-ggplot-coding
# 
# forest_indiv <- function(form_df, wrapit=FALSE) {
#    
#     plot1 = ggplot(data=form_df,
#     aes(x = Parameter,y = Coefficient, ymin = CI_low, ymax = CI_high))+
#     # geom_point(size=3, shape=19)+ # use only if not going to use color
#     geom_pointrange(aes(col=Group), show.legend = FALSE)+ ## this is good, but creates a legend
#     geom_hline(aes(fill=Parameter), yintercept =1, linetype=3)+
#     xlab('Parameter') + ylab("95% Confidence Interval")+
#     geom_errorbar(aes(ymin=CI_low, ymax=CI_high,col=Group), show.legend = FALSE, width=0,cex=.5)+ 
#     geom_text(aes(x = Parameter, label =  paste0(Coefficient, p.vales)), nudge_x = .35) + #size=3
#     coord_flip() + 
# 
#     theme(plot.title=element_text(size=16,face="bold"),
#         axis.text.y=element_text(size=12),
#         axis.ticks.y=element_blank(),
#         axis.text.x=element_text(face="bold"),
#         axis.title=element_text(size=12,face="bold"),
#         strip.text.y = element_text(hjust=0,vjust = 1,angle=180,face="bold"))+
#       
#     if (wrapit == TRUE) {
#       facet_grid(~Model,scales = "free",switch="y")
#     }
#     return(plot1)
# }
```
 
```{r, echo=FALSE}
# p1.1 = forest_indiv(filter(df.lex2, Model=="Binomial Logistic Mixed Effects")) + ggtitle("Lexical\nBinomial Logistic Mixed Effects") + ylim(.5, 2.5)
# p1.1
```

```{r, echo=FALSE}
# p1.2 = forest_indiv(filter(df.lex2, Model=="Gamma Mixed Effects")) + ggtitle("Lexical\nGamma Mixed Effects") + 
#   theme(axis.text.y=element_blank(),
#         axis.title.y=element_blank()) + 
#   ylim(.85, 1.15)
# p1.2
```
 
```{r, echo=FALSE}
# # p3 = forest_indiv(df.lex2, wrapit=TRUE); p3
# p1.1 + p1.2
```




<!-- coefficient table w/ tab_model  -->

```{r, echo=FALSE}
# tab_model(zigamma_lex, zigamma_syn2nd,
#           show.ci = 0.95, #FALSE
#           rm.terms = c("Block.l.Q"),
#           pred.labels = c("ordering_prop"="Utterance order", "Block.l.L"="Block (linear trend)", "BlockExpBlock2"="Block 2 (vs Warmup)", "aligner_rolecontroller"="Role [controller]", "relative_start_timeZ"="Level start time", "level_durationZ"="Level duration", "utterlen_alignerZ"="Utterance length", "ConceptPoT" = "Concept [PoT]", "Revisited_birevisit" = "Revisit [yes]", "XQ_know"="Familiarity [yes]", "femdomin"="Majority Female [yes]"),
#           # title = "",
#           digits = 3,
#           digits.re = 3,
#           dv.labels = c("Lexical", "Syntactic"),
#           show.re.var = TRUE,
#           use.viewer = TRUE)

```



<!-- glmmTMB approach -->

<!-- To start, going to build with a glmmTMB model that allows random effect structure. We are going to use the gamma distribution because we are dealing with non-integer (non-count) data as our DV and thus is continuously distributed, with some skew in the positive direction. Starting with the simplest random effect structure model with subject.  -->

```{r, echo=FALSE}
# zigamma_lex2 <- glmmTMB(lexical ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept + (aligner_role|subject_id),
#                          family = ziGamma(link = "log"), 
#                          ziformula = ~ ordering_prop + Block.l + aligner_role + relative_start_timeZ + level_durationZ + utterlen_alignerZ + Concept + (aligner_role|subject_id),
#                          data = main.data.20)
```




<!-- Better notes on useful papers for doing the above analysis (01/14/22): -->

```{r, echo=FALSE}
# *   Some reading on on comparing log-likelihood/AIC with various tests:
#   * Basics on AIC (uses LL and K [number of parameters, penalized for too many]) and can be used for non-embedded models (just so long as the link function is the same)
# https://www.scribbr.com/statistics/akaike-information-criterion/#:~:text=The%20Akaike%20information%20criterion%20(AIC,best%20fit%20for%20the%20data.  
# 
#     * AICtab approach recommended by Bolker et al for GLMMtmb type of approaches for model selection (note: does not attempt to give a p-value): https://journal.r-project.org/archive/2017/RJ-2017-066/RJ-2017-066.pdf
# 
#     * Another example of AICtab approach being used: http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html (scroll to section) http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/bolker_chap.html 
# 
#     * Suggestions on what to report when running an AICtab test: https://www.ashander.info/posts/2015/10/model-selection-glms-aic-what-to-report/
# 
#     * Expresses skepticism of relying too heavily on the p-value for the lrtest approach with generalized mixed models: https://www.ssc.wisc.edu/sscc/pubs/MM/MM_TestEffects.html#test-of-random-parameters

# There is also the issue of over-dispersion that we could test or examine, but might be overkill given gamma distribution accounts for overdispersion. 
# 
#   * library(aods3); gof()


## what do you call the expoentiated coefficient from a continuous outcome of a gamma model? not comparing the odds ratio, but the ratio of the means. Going to just go with "rate ratio" for rate of alignment. 
# https://stats.stackexchange.com/questions/504123/terminology-for-exponentiated-coefficients-from-glms-without-a-time-offset/555520#555520
# https://stats.stackexchange.com/questions/487563/term-for-expbeta-from-a-gamma-glm?rq=1

```



```{r, echo=FALSE}
# Other notes from 11/19/21:
# 
# A very good paper for just talking about the random effect structure of LMER models, ensures that what is being reported is accurate and gives a critical citation: http://www.singmann.org/download/publications/singmann_kellen-introduction-mixed-models.pdf
# 
# An interesting discussion of how to determine whether the random effects variables are worth including, whether a mixed effects model is even necessary. Brings up the interesting idea of using models with and without the effect and comparing with AIC
# https://stats.stackexchange.com/questions/56150/how-can-i-test-whether-a-random-effect-is-significant
# 
# In one of the responses to the main thread, a very good point that "although there is 'obviously' variation in subject performance, the extent of this subject variation can be fully or virtually-fully explained by just the residual variance term alone. There is not enough additional subject-level variation to warrant adding an additional subject-level random effect to explain all the observed variation."
# https://stats.stackexchange.com/questions/115090/why-do-i-get-zero-variance-of-a-random-effect-in-my-mixed-model-despite-some-va
# 
# Not the greatest post, but makes the point that gamma works on continuous non-negative distributions, whereas poisson and negative binomial do not:
# https://timothy-barry.github.io/posts/2020-06-16-gamma-poisson-nb/
# 
# ********Topic: Overdispersion
# Not sure whether I need to explicity test for this or not, as visually, it appears to be overdispersed. However, need to plot the residuals to know for sure. So, strike previous comment. Cannot merely plot the DV to make a determination. 
# Just ok resources but useable to back up some claims. 
# https://biometry.github.io/APES/LectureNotes/2016-JAGS/Overdispersion/OverdispersionJAGS.pdf
# https://biometry.github.io/APES//LectureNotes/2016-JAGS/Overdispersion/OverdispersionJAGS.html
# 
# *******Topic: "How to model non-negative zero-inflated continuous data?"
# Given this is exactly what I'm trying to do, this thread was helpful and pointed to the need of running zero-inflated/hurdle models (i.e., two-part models) 
# https://stats.stackexchange.com/questions/187824/how-to-model-non-negative-zero-inflated-continuous-data
# 
# But this post also suggests running a model where you run the two parts yourself rather than relying on a single function, like glmmTMB, especially if I want to build a model without the random effects structure. This tutorial shows you how:
# https://seananderson.ca/2014/05/18/gamma-hurdle/
# 
# This seananderson paper is really useful as it does make the points that most packages are built for count data (and he lists a bunch of these options), but this doesn't help me much. He also reinforces the point that what is needed are binomial-Gamma hurdle models. 
# 
# Use this paper when citing glmmTMB models:
# https://journal.r-project.org/archive/2017/RJ-2017-066/RJ-2017-066.pdf

```













